3.	Write a program to find the word frequency in a given file

from pyspark import SparkContext
from operator import add

sc = SparkContext(appName="Words")
lines = sc.textFile(sys.argv[1], 1)  # this is an RDD

# counts is an rdd is of the form (word, count)
counts = lines.flatMap(lambda x: [(w.lower(), 1) for w in x.split()]).reduceByKey(add)

# collect brings it to a list in local memory
output = counts.collect()
for (word, count) in output:
    print "%s: %i" % (word, count)

sc.stop()  # stop the spark context
